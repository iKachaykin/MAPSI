{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME sur la classification de lettres manuscrites\n",
    "## Format des données\n",
    "Nous travaillerons sur des lettres manuscrites.\n",
    "Les données sont fournies au format pickle (le standard de sérialisation python, particulièrement convivial). Pour les charger : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('ressources/lettres.pkl', 'rb') as f:\n",
    "    data = pkl.load(f, encoding='latin1') \n",
    "X = np.array(data.get('letters')) # récupération des données sur les lettres\n",
    "Y = np.array(data.get('labels')) # récupération des étiquettes associées "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont dans un format original: une lettre est en fait une série d'angles (exprimés en degrés). Un exemple: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36.214493, 347.719116, 322.088898, 312.230957, 314.851013,\n",
       "       315.487213, 313.556702, 326.534973, 141.288971, 167.606689,\n",
       "       199.321594, 217.911087, 226.443298, 235.002472, 252.354492,\n",
       "       270.045654, 291.665161, 350.934723,  17.892815,  20.281025,\n",
       "        28.207161,  43.883423,  53.459026])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_num = X[0].size  # On stocke le nombre des états de chaque signal pour l'utiliser plus tard\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'acquisition, un stylo intelligent a pris des mesures régulièrement dans le temps: chaque période correspond à un segment de droite et le stylo a calculé l'angle entre deux segments consécutifs... C'est l'information qui vous est fournie.\n",
    "\n",
    "Pour afficher une lettre, il faut reconstruire la trajectoire enregistrée... C'est ce que fait la méthode ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# affichage d'une lettre\n",
    "def tracerLettre(let):\n",
    "    a = -let*np.pi/180; # conversion en rad\n",
    "    coord = np.array([[0, 0]]); # point initial\n",
    "    for i in range(len(a)):\n",
    "        x = np.array([[1, 0]]);\n",
    "        rot = np.array([[np.cos(a[i]), -np.sin(a[i])],[ np.sin(a[i]),np.cos(a[i])]])\n",
    "        xr = x.dot(rot) # application de la rotation\n",
    "        coord = np.vstack((coord,xr+coord[-1,:]))\n",
    "    plt.figure()\n",
    "    plt.plot(coord[:,0],coord[:,1])\n",
    "    plt.savefig(\"exlettre.png\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracerLettre(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Apprentissage d'un modèle CM (max de vraisemblance)\n",
    "### 1. Discrétisation\n",
    "\n",
    "**1 état = 1 angle**\n",
    "\n",
    "Il est nécessaire de regrouper les angles en un nombre fini d'états (par exemple 20)\n",
    "- définir un `intervalle = 360 / n_etats`\n",
    "- discrétiser tous les signaux à l'aide de la formule `np.floor(x / intervalle)`\n",
    "\n",
    "Donner le code de la méthode `discretise(x, d)` qui prend la base des signaux et retourne une base de signaux discrétisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0,\n",
      "       0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0,\n",
      "       0])\n",
      " array([2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0,\n",
      "       0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0,\n",
      "       0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0,\n",
      "       0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0])\n",
      " array([0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0,\n",
      "       0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1,\n",
      "       1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1,\n",
      "       1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,\n",
      "       1, 1, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1,\n",
      "       1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1,\n",
      "       1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1])\n",
      " array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([0, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0])\n",
      " array([2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
      "       0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0,\n",
      "       0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 0])\n",
      " array([0, 1, 1, 1, 2]) array([1, 1, 1, 1]) array([1, 1, 1, 1, 1, 2])\n",
      " array([0, 1, 1, 1]) array([1, 1, 2, 2, 2]) array([1, 1, 1, 1])\n",
      " array([1, 1, 1, 2, 2, 2]) array([0, 1, 1, 1, 2, 2])\n",
      " array([1, 2, 2, 2, 2]) array([1, 1, 2, 2]) array([1, 1, 2, 2])\n",
      " array([1, 1]) array([1, 1]) array([1, 1]) array([1, 1]) array([1, 1, 2])\n",
      " array([1, 2, 2]) array([1, 1, 1]) array([1, 1, 1]) array([1, 1, 1, 2])\n",
      " array([1, 1, 1]) array([1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2])\n",
      " array([0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1])\n",
      " array([0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      " array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1])\n",
      " array([1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      " array([1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      " array([1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1])\n",
      " array([1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1])\n",
      " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1,\n",
      "       1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1,\n",
      "       1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1,\n",
      "       1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1,\n",
      "       1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1,\n",
      "       1, 1])\n",
      " array([2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       1, 1, 1])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2, 1, 1])\n",
      " array([0, 1, 1, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([0, 1, 1, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([2, 1, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 1, 1])\n",
      " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1])\n",
      " array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1])\n",
      " array([1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1])\n",
      " array([2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) array([2, 2, 2, 2, 2, 2])\n",
      " array([2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0,\n",
      "       0, 0])\n",
      " array([0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0,\n",
      "       0, 0, 0, 0])\n",
      " array([0, 0, 2, 2, 0, 0, 0, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0,\n",
      "       0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0,\n",
      "       0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0,\n",
      "       0, 2, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0])\n",
      " array([0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0,\n",
      "       0, 0, 0])\n",
      " array([0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0,\n",
      "       0, 0, 0, 2, 2])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afin d'implementer cette fonction demandée on n'utilise que les expressions de NumPy\n",
    "def discretise(x, d):\n",
    "    intervalle = 360 / d\n",
    "    return np.array([np.array(np.floor(xi), dtype=int) for xi in x / intervalle])\n",
    "\n",
    "# En décommentant ligne du code ci-dessous, vous pouvez vérifier que cette fonction marche\n",
    "# aussi dans le cas où on a pour x le tableau des signaux\n",
    "# print(discretise(X, 3))\n",
    "discretise(X[0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION :** code du premier signal avec une discrétisation sur 3 états:\n",
    "```python\n",
    "array([ 0.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  1., 1., 1., 2., 2.,  2.,\n",
    "       2.,  0.,  0.,  0.,  0.,  0.])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regrouper les indices des signaux par classe (pour faciliter l'apprentissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]),\n",
       " array([22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]),\n",
       " array([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]),\n",
       " array([44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]),\n",
       " array([55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]),\n",
       " array([66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76]),\n",
       " array([77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]),\n",
       " array([88, 89, 90, 91, 92, 93, 94, 95, 96, 97]),\n",
       " array([ 98,  99, 100, 101, 102, 103, 104, 105, 106, 107]),\n",
       " array([108, 109, 110, 111, 112, 113, 114, 115, 116, 117]),\n",
       " array([118, 119, 120, 121, 122, 123, 124, 125, 126, 127]),\n",
       " array([128, 129, 130, 131, 132, 133, 134, 135, 136, 137]),\n",
       " array([138, 139, 140, 141, 142, 143, 144, 145, 146, 147]),\n",
       " array([148, 149, 150, 151, 152, 153, 154, 155, 156, 157]),\n",
       " array([158, 159, 160, 161, 162, 163, 164, 165, 166, 167]),\n",
       " array([168, 169, 170, 171, 172, 173, 174, 175, 176, 177]),\n",
       " array([178, 179, 180, 181, 182, 183, 184, 185, 186, 187]),\n",
       " array([188, 189, 190, 191, 192, 193, 194, 195, 196, 197]),\n",
       " array([198, 199, 200, 201, 202, 203, 204, 205, 206, 207]),\n",
       " array([208, 209, 210, 211, 212, 213, 214, 215, 216, 217]),\n",
       " array([218, 219, 220, 221, 222, 223, 224, 225, 226, 227]),\n",
       " array([228, 229, 230, 231, 232, 233, 234, 235, 236, 237]),\n",
       " array([238, 239, 240, 241, 242, 243, 244, 245, 246, 247]),\n",
       " array([248, 249, 250, 251, 252, 253, 254, 255, 256, 257]),\n",
       " array([258, 259, 260, 261, 262, 263, 264, 265, 266, 267])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def groupByLabel(y):\n",
    "    index = []\n",
    "    for i in np.unique(y): # pour toutes les classes\n",
    "        ind, = np.where(y == i)\n",
    "        index.append(ind)\n",
    "    return index\n",
    "\n",
    "groupByLabel(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode produit simplement une structure type:\n",
    "```python\n",
    "[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
    " array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]),\n",
    " array([22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]),\n",
    " array([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]),\n",
    " array([44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]),\n",
    " array([55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]),\n",
    " ...\n",
    "```\n",
    "Chaque ligne regroupe les indices de signaux correspondant à une classe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Apprendre les modèles CM\n",
    "\n",
    "Soit {$X_C$} la base de signaux discrétisés correspondant à une classe {$C$} et {$d$} le nombre d'états. Donner le code de la fonction `learnMarkovModel(Xc, d)` qui retourne un tuple contenant Pi et A.\n",
    "\n",
    "Rappel:\n",
    "- Initialisation de \n",
    "```python\n",
    " A = np.zeros((d, d))\n",
    " Pi = np.zeros(d)```\n",
    "- Parcours de tous les signaux et incréments de A et Pi\n",
    "- Normalisation (un peu réfléchie pour éviter les divisions par 0)\n",
    "```python\n",
    "A = A / np.maximum(A.sum(1).reshape(d, 1), 1) # normalisation\n",
    "Pi = Pi / Pi.sum()```\n",
    "\n",
    "**Note** : la solution proposée pour gérer le cas des lignes entièrement à 0 est naïve et n'est pas totalement satisfaisante. Comprendre pourquoi. On proposera une solution améliorée plus loin dans le TME. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.36363636, 0.        , 0.63636364]),\n",
       " array([[0.84444444, 0.06666667, 0.08888889],\n",
       "        [0.        , 0.83333333, 0.16666667],\n",
       "        [0.11382114, 0.06504065, 0.82113821]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On estime les paramètres Pi et A\n",
    "# Pi : pour chaque signal on compte combien de fois signal est commencé par quelque état\n",
    "# A : pour chaque signal on compte combien de fois quelque état fait une transition à\n",
    "# quelque autre état\n",
    "def learnMarkovModel(Xc, d):\n",
    "    Pi, A = np.zeros(d), np.zeros((d, d))\n",
    "    for Xc_i in Xc:\n",
    "        Pi[Xc_i[0]] += 1                                    # comptage pour Pi\n",
    "        for state_index in range(len(Xc_i)-1):\n",
    "            A[Xc_i[state_index], Xc_i[state_index+1]] += 1  # comptage pour A\n",
    "    \n",
    "    # normalisation\n",
    "    Pi = Pi / Pi.sum() if Pi.sum() != 0 else Pi\n",
    "    A = A / np.maximum(A.sum(1).reshape(d, 1), 1)\n",
    "    return Pi, A\n",
    "\n",
    "learnMarkovModel(discretise(X[groupByLabel(Y)[0]], 3), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation :** premier modèle avec une discrétisation sur 3 états :\n",
    "```python\n",
    "(array([ 0.36363636,  0.        ,  0.63636364]),\n",
    " array([[ 0.84444444,  0.06666667,  0.08888889],\n",
    "       [ 0.        ,  0.83333333,  0.16666667],\n",
    "       [ 0.11382114,  0.06504065,  0.82113821]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stocker les modèles dans une liste\n",
    "\n",
    "Pour un usage ultérieur plus facile, on utilise le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On crée des modèles pour d = 3\n",
    "d = 3                   # paramètre de discrétisation\n",
    "Xd = discretise(X, d)    # application de la discrétisation\n",
    "index = groupByLabel(Y)  # groupement des signaux par classe\n",
    "models = []\n",
    "for cl in range(len(np.unique(Y))): # parcours de toutes les classes et optimisation des modèles\n",
    "    models.append(learnMarkovModel(Xd[index[cl]], d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test (affectation dans les classes sur critère MV)\n",
    "### 1. (log)Probabilité d'une séquence dans un modèle\n",
    "\n",
    "Donner le code de la méthode `probaSequence(s,Pi,A)` qui retourne la log-probabilité d'une séquence `s` dans le modèle {$\\lambda=\\{Pi,A\\}$} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivankachaikin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-13.491086  ,         -inf,         -inf,         -inf,\n",
       "               -inf,         -inf,         -inf,         -inf,\n",
       "               -inf,         -inf,         -inf,         -inf,\n",
       "               -inf,         -inf,         -inf,         -inf,\n",
       "               -inf,         -inf,         -inf,         -inf,\n",
       "               -inf,         -inf,         -inf,         -inf,\n",
       "               -inf, -12.48285678])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On calcule log de la proba demandée en utilisant une formule : \n",
    "# P(S = (s_1, s_2, ..., s_T)) = P(s_1) * P(s_2 | s_1)* ... * P(s_T | s_{T-1})\n",
    "# où la proba première est donnée par Pi et toutes les autres sont données par A, en fait\n",
    "def probaSequence(s, Pi, A):\n",
    "    prob = Pi[s[0]]\n",
    "    for state_ind in range(1, len(s)):\n",
    "        prob *= A[s[state_ind-1], s[state_ind]]\n",
    "        \n",
    "    return np.log(prob)\n",
    "\n",
    "res = []\n",
    "# on calcule log de proba pour tous les modèles et on les affiche\n",
    "for model in models:\n",
    "    Pi, A = model\n",
    "    res.append(probaSequence(discretise(X[0], 3), Pi, A))\n",
    "np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION :** probabilité du premier signal dans les 26 modèles avec une discrétisation sur 3 états :\n",
    "```python\n",
    "array([-13.491086  ,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf,         -inf,         -inf,         -inf,\n",
    "               -inf, -12.48285678])\n",
    "```\n",
    "\n",
    "- Ce signal est-il bien classé ?\n",
    "- D'où viennent tous les `-inf` ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Application de la méthode précédente pour tous les signaux et tous les modèles de lettres\n",
    "\n",
    "L'application se fait en une ligne de code si vous avez respecté les spécifications précédentes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivankachaikin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# On recrée des modèles pour d = 20\n",
    "d = 20                   # paramètre de discrétisation\n",
    "Xd = discretise(X, d)    # application de la discrétisation\n",
    "index = groupByLabel(Y)  # groupement des signaux par classe\n",
    "models = []\n",
    "for cl in range(len(np.unique(Y))): # parcours de toutes les classes et optimisation des modèles\n",
    "    models.append(learnMarkovModel(Xd[index[cl]], d))\n",
    "\n",
    "proba = np.array([[probaSequence(Xd[i], models[cl][0], models[cl][1]) for i in range(len(Xd))]\n",
    "                  for cl in range(len(np.unique(Y)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation des performances\n",
    "\n",
    "Pour l'évaluation, nous proposons l'approche suivante: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.914179104477612"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcul d'une version numérique des Y :\n",
    "Ynum = np.zeros(Y.shape)\n",
    "for num, char in enumerate(np.unique(Y)):\n",
    "    Ynum[Y == char] = num\n",
    "    \n",
    "# print(Y)\n",
    "# print(Ynum)\n",
    "    \n",
    "# Calcul de la classe la plus probable :\n",
    "pred = proba.argmax(0) # max colonne par colonne\n",
    "# print(pred)\n",
    "\n",
    "# Calcul d'un pourcentage de bonne classification :\n",
    "np.where(pred != Ynum, 0.,1.).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INDICE DE PERFORMANCE :** 91% de bonne classification avec 20 états, 69% avec 3 états"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biais d'évaluation, notion de sur-apprentissage\n",
    "\n",
    "Dans le protocole précédent, nous avons triché:\n",
    "- les données servent d'abord à apprendre les modèles...\n",
    "- puis nous nous servons des mêmes données pour tester les modèles ! Les performances sont forcément bonnes ! \n",
    "\n",
    "Afin de palier le problème, nous allons diviser en deux la base de données: une partie servira à l'apprentissage des modèles, l'autre à leur évaluation. Pour effectuer la division, nous fournissons le code suivant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separation app/test, pc=ratio de points en apprentissage\n",
    "def separeTrainTest(y, pc):\n",
    "    indTrain = []\n",
    "    indTest = []\n",
    "    for i in np.unique(y): # pour toutes les classes\n",
    "        ind, = np.where(y == i)\n",
    "        n = len(ind)\n",
    "        indTrain.append(ind[np.random.permutation(n)][:int(np.floor(pc * n))])\n",
    "        indTest.append(np.setdiff1d(ind, indTrain[-1]))\n",
    "    return indTrain, indTest\n",
    "\n",
    "# exemple d'utilisation\n",
    "itrain, itest = separeTrainTest(Y, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dans `itrain`, nous obtenons les indices des signaux qui doivent servir en apprentissage pour chaque classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 6,  7,  9, 10,  5,  2,  1,  0]),\n",
       " array([11, 13, 20, 21, 18, 19, 17, 14]),\n",
       " array([27, 23, 30, 22, 32, 25, 28, 29]),\n",
       " array([37, 36, 42, 43, 35, 38, 39, 34]),\n",
       " array([50, 52, 48, 51, 46, 49, 45, 53]),\n",
       " array([57, 60, 65, 61, 58, 64, 56, 55]),\n",
       " array([73, 71, 72, 74, 75, 70, 69, 66]),\n",
       " array([81, 77, 84, 80, 83, 87, 82, 78]),\n",
       " array([93, 92, 91, 95, 97, 89, 90, 94]),\n",
       " array([107, 106, 101, 103, 104, 100,  98, 102]),\n",
       " array([110, 109, 112, 113, 111, 108, 116, 115]),\n",
       " array([122, 124, 127, 123, 126, 119, 118, 125]),\n",
       " array([132, 133, 136, 129, 137, 131, 135, 134]),\n",
       " array([142, 144, 139, 143, 138, 141, 145, 140]),\n",
       " array([157, 148, 153, 152, 149, 150, 154, 155]),\n",
       " array([163, 158, 164, 165, 159, 160, 167, 162]),\n",
       " array([169, 170, 176, 175, 177, 168, 172, 171]),\n",
       " array([186, 182, 187, 180, 184, 179, 178, 185]),\n",
       " array([190, 195, 194, 197, 192, 189, 188, 196]),\n",
       " array([200, 205, 202, 203, 207, 198, 206, 199]),\n",
       " array([214, 208, 209, 216, 210, 213, 211, 217]),\n",
       " array([224, 219, 227, 226, 225, 223, 221, 222]),\n",
       " array([234, 229, 228, 230, 236, 235, 232, 233]),\n",
       " array([246, 245, 247, 238, 240, 242, 239, 244]),\n",
       " array([256, 250, 249, 254, 255, 253, 257, 248]),\n",
       " array([267, 259, 264, 265, 260, 266, 263, 261])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** pour faciliter l'évaluation des modèles, vous aurez besoin de re-fusionner tous les indices d'apprentissage et de test. Cela se fait avec les lignes de code suivantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 9, 10, 5, 2, 1, 0, 11, 13, 20, 21, 18, 19, 17, 14, 27, 23, 30, 22, 32, 25, 28, 29, 37, 36, 42, 43, 35, 38, 39, 34, 50, 52, 48, 51, 46, 49, 45, 53, 57, 60, 65, 61, 58, 64, 56, 55, 73, 71, 72, 74, 75, 70, 69, 66, 81, 77, 84, 80, 83, 87, 82, 78, 93, 92, 91, 95, 97, 89, 90, 94, 107, 106, 101, 103, 104, 100, 98, 102, 110, 109, 112, 113, 111, 108, 116, 115, 122, 124, 127, 123, 126, 119, 118, 125, 132, 133, 136, 129, 137, 131, 135, 134, 142, 144, 139, 143, 138, 141, 145, 140, 157, 148, 153, 152, 149, 150, 154, 155, 163, 158, 164, 165, 159, 160, 167, 162, 169, 170, 176, 175, 177, 168, 172, 171, 186, 182, 187, 180, 184, 179, 178, 185, 190, 195, 194, 197, 192, 189, 188, 196, 200, 205, 202, 203, 207, 198, 206, 199, 214, 208, 209, 216, 210, 213, 211, 217, 224, 219, 227, 226, 225, 223, 221, 222, 234, 229, 228, 230, 236, 235, 232, 233, 246, 245, 247, 238, 240, 242, 239, 244, 256, 250, 249, 254, 255, 253, 257, 248, 267, 259, 264, 265, 260, 266, 263, 261]\n",
      "[3, 4, 8, 12, 15, 16, 24, 26, 31, 33, 40, 41, 44, 47, 54, 59, 62, 63, 67, 68, 76, 79, 85, 86, 88, 96, 99, 105, 114, 117, 120, 121, 128, 130, 146, 147, 151, 156, 161, 166, 173, 174, 181, 183, 191, 193, 201, 204, 212, 215, 218, 220, 231, 237, 241, 243, 251, 252, 258, 262]\n"
     ]
    }
   ],
   "source": [
    "ia = []\n",
    "for i in itrain:\n",
    "    ia += i.tolist()    \n",
    "it = []\n",
    "for i in itest:\n",
    "    it += i.tolist()\n",
    "print(ia)\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 2 :** Du fait de la permutation aléatoire, les résultats vont bouger (un peu) à chaque execution du programme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions importantes\n",
    "- Ré-utiliser les fonctions précédemment définies pour apprendre des modèles et les évaluer sans biais.\n",
    "- Calculer et analyser les résultats obtenus en apprentissage et en test\n",
    "- Etudier l'évolution des performances en fonction de la discrétisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'a' 'a' 'b' 'b' 'b' 'c' 'c' 'c' 'd' 'd' 'd' 'e' 'e' 'e' 'f' 'f' 'f'\n",
      " 'g' 'g' 'g' 'h' 'h' 'h' 'i' 'i' 'j' 'j' 'k' 'k' 'l' 'l' 'm' 'm' 'n' 'n'\n",
      " 'o' 'o' 'p' 'p' 'q' 'q' 'r' 'r' 's' 's' 't' 't' 'u' 'u' 'v' 'v' 'w' 'w'\n",
      " 'x' 'x' 'y' 'y' 'z' 'z']\n",
      "[ 0  0  0  1  1  1  2  2  2  3  3  3  4  4  4  5  5  5  6  6  6  7  7  7\n",
      "  8  8  9  9 10 10 11 11 12 12 13 13 14 14 15 15 16 16 17 17 18 18 19 19\n",
      " 20 20 21 21 22 22 23 23 24 24 25 25]\n",
      "[ 0  0  0  1  1  1  2  2 14  3  0  0  4  4  4  6  5 19  6 19  6  7  7  1\n",
      "  8 13  9  9 10 10 19 19 12  7 13 13 14 14  1 15 16 16  7 21 18 18 19 19\n",
      " 14 22 21 21  0  0 23 23  0 24 25 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivankachaikin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6833333333333333"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on crée des modèles à partir de l'échantillon de l'apprentissage en utilisant les index \n",
    "# obtenus ci-dessus\n",
    "d = 5                              # paramètre de discrétisation\n",
    "Xd_train = discretise(X[ia], d)    # application de la discrétisation\n",
    "Xd_test = discretise(X[it], d)\n",
    "index = itrain.copy()\n",
    "models = []\n",
    "for cl in range(len(np.unique(Y))): # parcours de toutes les classes et optimisation des modèles\n",
    "    models.append(learnMarkovModel(discretise(X[index[cl]], d), d))\n",
    "\n",
    "# on calcule les logs proba pour tous les modèles et pour tous les signaux de l'échantillon de tests\n",
    "proba = np.array([[probaSequence(Xd_test[i], models[cl][0], models[cl][1]) for i in range(len(Xd_test))]\n",
    "                  for cl in range(len(np.unique(Y)))])\n",
    "\n",
    "# calcul d'une version numérique des Y :\n",
    "Ynum_test = np.zeros(Y[it].shape)\n",
    "for num, char in enumerate(np.unique(Y)):\n",
    "    Ynum_test[Y[it] == char] = num\n",
    "\n",
    "# pour être sûr, on affiche étiquettes symboliques, celles numériques et une prédiction\n",
    "print(Y[it])\n",
    "print(np.array(Ynum_test, dtype=int))\n",
    "    \n",
    "# Calcul de la classe la plus probable :\n",
    "pred = proba.argmax(0) # max colonne par colonne\n",
    "print(pred)\n",
    "\n",
    "# Calcul d'un pourcentage de bonne classification :\n",
    "np.where(pred != Ynum_test, 0.,1.).mean()\n",
    "\n",
    "# On peut conclure que notre modèle reconnaît plus ou moins des lettres introduites. En fait,\n",
    "# pour tout d compris dans [3..10] on obtient en moyen plus de moitié de formes bien reconnues\n",
    "# parmis l'échantillon de tests. De plus, on voit qu'on atteint la meilleur classification\n",
    "# en moyen lorsque d = 5, avec un pourcentage moyen de bonne classification de ≈68.333%.\n",
    "# Néanmoins, il semble intéressant de tester ce modèle sur les données différentes,\n",
    "# particulièrement, sur une autre échantillon de lettres. En outre, il faut aussi appliquer\n",
    "# notre modèle à l'échantillon mélangé pour considérer les écriture diverses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lutter contre le sur-apprentissage\n",
    "Cette base de données met en lumière le phénomène de sur-apprentissage : il y a peu de données et dès que le nombre d'états augmente, il y a trop peu d'exemple pour estimer correctement les matrices {$A, \\pi$}. De nombreuses cases sont donc à 0, voire des lignes entières (d'où la sécurisation du code pour la normalisation des matrices stochastiques).\n",
    "\n",
    "Ces 0 sont particulièrement discriminants: considérant la classe {$c$}, ils permettent d'éliminer de cette classe tout signal présentant cette caractéristique. Cette règle est trop forte compte tenu de la taille de la base d'apprentissage. Nous proposons une astuce pour palier cette faiblesse : lors du comptage, initialiser les matrices {$A, \\pi$} avec ones au lieu de zeros . On fait semblant d'avoir observer une transition de chaque type avant même le début du comptage.\n",
    "\n",
    "Comparer les performances en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On définit une fonction alternative\n",
    "def learnMarkovModel_alternative(Xc, d):\n",
    "    Pi, A = np.ones(d), np.ones((d, d))  #l'initialisation différent\n",
    "    for Xc_i in Xc:\n",
    "        Pi[Xc_i[0]] += 1\n",
    "        for state_index in range(len(Xc_i)-1):\n",
    "            A[Xc_i[state_index], Xc_i[state_index+1]] += 1\n",
    "    \n",
    "    Pi = Pi / Pi.sum() if Pi.sum() != 0 else Pi\n",
    "    A = A / np.maximum(A.sum(1).reshape(d, 1), 1)\n",
    "    \n",
    "    return Pi, A\n",
    "\n",
    "d = 10                              # paramètre de discrétisation\n",
    "Xd_train = discretise(X[ia], d)    # application de la discrétisation\n",
    "Xd_test = discretise(X[it], d)\n",
    "index = itrain.copy()\n",
    "models = []\n",
    "for cl in range(len(np.unique(Y))): # parcours de toutes les classes et optimisation des modèles\n",
    "    models.append(learnMarkovModel_alternative(discretise(X[index[cl]], d), d))\n",
    "\n",
    "\n",
    "proba_alt = np.array([[probaSequence(Xd_test[i], models[cl][0], models[cl][1]) for i in range(len(Xd_test))]\n",
    "                      for cl in range(len(np.unique(Y)))])\n",
    "\n",
    "# calcul d'une version numérique des Y :\n",
    "Ynum_test_alt = np.zeros(Y[it].shape)\n",
    "for num, char in enumerate(np.unique(Y)):\n",
    "    Ynum_test_alt[Y[it] == char] = num\n",
    "    \n",
    "# Calcul de la classe la plus probable :\n",
    "pred_alt = proba_alt.argmax(0) # max colonne par colonne\n",
    "\n",
    "# Calcul d'un pourcentage de bonne classification :\n",
    "np.where(pred_alt != Ynum_test_alt, 0.,1.).mean()\n",
    "\n",
    "# Dans ce cas, on peut observer l'amélioration des résultats. Par contre, il ne s'agit pas de\n",
    "# changements significatifs. En général, on voit qu'on améliore plutôt la précision de\n",
    "# classification pour plusieurs d tandis que celle maximale de type maximale reste assez proche.\n",
    "# Par exemple, on obtient souvent ici l'exactitude maximale de 70% au lieu de ≈68.333% du\n",
    "# modèle précédent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie optionnelle\n",
    "## Evaluation qualitative\n",
    "\n",
    "Nous nous demandons maintenant où se trouvent les erreurs que nous avons commises...\n",
    "\n",
    "Calcul de la matrice de confusion: pour chaque échantillon de test, nous avons une prédiction (issue du modèle) et une vérité terrain (la vraie étiquette). En posant Nc le nombre de classes, la matrice de confusion est une matrice (Nc x Nc) où nous comptons le nombre d'échantillon de test dans chaque catégorie :\n",
    "\n",
    "- Initialisation à 0 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = np.zeros((26,26), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pour chaque échantillon, incrément de la case (prediction, vérité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcours de toutes étiquettes et de toutes predictions\n",
    "for cl_pred, cl_real in zip(pred, np.array(Ynum_test, dtype=int)):\n",
    "    conf[cl_pred, cl_real] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tracé de la matrice : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(conf, interpolation = 'nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(26), np.unique(Y))\n",
    "plt.yticks(np.arange(26), np.unique(Y))\n",
    "plt.xlabel(u'Vérité terrain')\n",
    "plt.ylabel(u'Prédiction')\n",
    "plt.savefig(\"mat_conf_lettres.png\")\n",
    "# De l'image obtenu on peut déduire que notre modèle reconnaît mal des lettres qui sont pareil\n",
    "# dans l'écriture française. Par exemple, on s'embrouille souvent dans les lettre 'a' et 'd',\n",
    "# 'g' et 'q', 't' et 'f', 'o' et 'b', 'a' et 'p'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle génératif\n",
    "\n",
    "Utiliser les modèles appris pour générer de nouvelles lettres manuscrites.\n",
    "\n",
    "### Tirage selon une loi de probabilité discrète\n",
    "\n",
    "- faire la somme cumulée de la loi {$sc$}\n",
    "- tirer un nombre aléatoire {$t$} entre 0 et 1\n",
    "- trouver la première valeur de {$sc$} qui est supérieure à {$t$}\n",
    "- retourner cet état \n",
    "\n",
    "**Note :** comme vu en cours, tout repose sur la somme cumulée (notée ici `sc$`, calculable en appelant `np.cumsum`. Sur un exemple: la loi `V = [0.2, 0.4, 0.3, 0.1]` a pour somme cumulée `V.cumsum() == [0.2,  0.6,  0.9,  1.0]`\n",
    "\n",
    "### Génération d'une séquence de longueur N\n",
    "\n",
    "- tirer un état {$s_0$} selon Pi\n",
    "- tant que la longueur n'est pas atteinte :\n",
    "  - tirer un état {$s_{t+1}$} selon {$A[s_{t}]$} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(Pi, A, d):\n",
    "    Pi_temp = Pi.copy()\n",
    "    res = []\n",
    "    \n",
    "    # pour chaque état qu'il faut remplir\n",
    "    for _ in range(states_num):\n",
    "        # on génére une valeur aléatoire de la distribution uniforme dans [0, 1]\n",
    "        rand_val = np.random.rand()\n",
    "#         print(rand_val)\n",
    "#         print(Pi_temp)\n",
    "#         print(Pi_temp.cumsum())\n",
    "        # on prend un état avec sa probabilité\n",
    "        state = np.arange(d)[Pi_temp.cumsum() > rand_val][0]\n",
    "#         print(state)\n",
    "#         print()\n",
    "        # on stocke un état courant\n",
    "        res.append(state)\n",
    "        # on met-à-jour les probabilités\n",
    "        Pi_temp = np.dot(Pi_temp, A)\n",
    "        \n",
    "    return np.array(res)\n",
    "    \n",
    "newa = generate(models[0][0], models[0][1], d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "newa = generate(models[0][0], models[0][1], d)       # generation d'une séquence d'états\n",
    "intervalle = 360. / d                                 # pour passer des états => valeur d'angles\n",
    "newa_continu = np.array([i * intervalle for i in newa]) # conv int => double\n",
    "tracerLettre(newa_continu)\n",
    "# On voit donc que ce modèle ne fonctionne pas vraiment bien pour génération des lettres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
